{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From data loading to running a forward pass\n",
    "In this exercise, you'll create a PyTorch DataLoader from a pandas DataFrame and call a model on this dataset. Specifically, you'll run a forward pass on a neural network. You'll continue working with fully connected neural networks, as you have done so far.\n",
    "\n",
    "You'll begin by subsetting a loaded DataFrame called dataframe, converting features and targets NumPy arrays, and converting to PyTorch tensors in order to create a PyTorch dataset.\n",
    "\n",
    "This dataset can be loaded into a PyTorch DataLoader, batched, shuffled, and used to run a forward pass on a custom fully connected neural network.\n",
    "\n",
    "NumPy as np, pandas as pd, torch, TensorDataset(), and DataLoader() have been imported for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' \\nThe Dataframe in DataCamp looks like this:\\nph  Hardness  Solids  Chloramines  Sulfate  Conductivity  Organic_carbon  Trihalomethanes  Turbidity  Potability\\n0     0.587     0.578   0.386        0.568    0.647         0.293           0.655            0.795      0.630           0\\n1     0.644     0.441   0.314        0.439    0.515         0.357           0.377            0.203      0.520           0\\n2     0.389     0.471   0.506        0.524    0.562         0.143           0.250            0.401      0.220           0\\n3     0.726     0.716   0.506        0.522    0.752         0.149           0.467            0.659      0.242           0\\n4     0.611     0.533   0.238        0.270    0.495         0.495           0.410            0.470      0.585           0\\n...     ...       ...     ...          ...      ...           ...             ...              ...        ...         ...\\n2006  0.636     0.581   0.278        0.418    0.522         0.342           0.310            0.403      0.627           1\\n2007  0.470     0.549   0.301        0.538    0.499         0.231           0.565            0.176      0.395           1\\n2008  0.818     0.087   0.656        0.671    0.369         0.432           0.563            0.286      0.579           1\\n2009  0.424     0.464   0.460        0.542    0.616         0.388           0.398            0.449      0.440           1\\n2010  0.322     0.493   0.841        0.492    0.656         0.589           0.471            0.503      0.592           1\\n\\n[2011 rows x 10 columns]'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" \n",
    "The Dataframe in DataCamp looks like this:\n",
    "ph  Hardness  Solids  Chloramines  Sulfate  Conductivity  Organic_carbon  Trihalomethanes  Turbidity  Potability\n",
    "0     0.587     0.578   0.386        0.568    0.647         0.293           0.655            0.795      0.630           0\n",
    "1     0.644     0.441   0.314        0.439    0.515         0.357           0.377            0.203      0.520           0\n",
    "2     0.389     0.471   0.506        0.524    0.562         0.143           0.250            0.401      0.220           0\n",
    "3     0.726     0.716   0.506        0.522    0.752         0.149           0.467            0.659      0.242           0\n",
    "4     0.611     0.533   0.238        0.270    0.495         0.495           0.410            0.470      0.585           0\n",
    "...     ...       ...     ...          ...      ...           ...             ...              ...        ...         ...\n",
    "2006  0.636     0.581   0.278        0.418    0.522         0.342           0.310            0.403      0.627           1\n",
    "2007  0.470     0.549   0.301        0.538    0.499         0.231           0.565            0.176      0.395           1\n",
    "2008  0.818     0.087   0.656        0.671    0.369         0.432           0.563            0.286      0.579           1\n",
    "2009  0.424     0.464   0.460        0.542    0.616         0.388           0.398            0.449      0.440           1\n",
    "2010  0.322     0.493   0.841        0.492    0.656         0.589           0.471            0.503      0.592           1\n",
    "\n",
    "[2011 rows x 10 columns]\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      ph  Hardness  Solids  Chloramines  Sulfate  Conductivity  \\\n",
      "0  0.587     0.578   0.386        0.568    0.647         0.293   \n",
      "1  0.644     0.441   0.314        0.439    0.515         0.357   \n",
      "2  0.389     0.471   0.506        0.524    0.562         0.143   \n",
      "3  0.726     0.716   0.506        0.522    0.752         0.149   \n",
      "4  0.611     0.533   0.238        0.270    0.495         0.495   \n",
      "\n",
      "   Organic_carbon  Trihalomethanes  Turbidity  Potability  \n",
      "0           0.655            0.795      0.630           0  \n",
      "1           0.377            0.203      0.520           0  \n",
      "2           0.250            0.401      0.220           0  \n",
      "3           0.467            0.659      0.242           0  \n",
      "4           0.410            0.470      0.585           0  \n"
     ]
    }
   ],
   "source": [
    "\"\"\"Here, I tried to write my own version:\"\"\"\n",
    "import pandas as pd\n",
    "\n",
    "# Provided data\n",
    "data = {\n",
    "    'ph': [0.587, 0.644, 0.389, 0.726, 0.611],\n",
    "    'Hardness': [0.578, 0.441, 0.471, 0.716, 0.533],\n",
    "    'Solids': [0.386, 0.314, 0.506, 0.506, 0.238],\n",
    "    'Chloramines': [0.568, 0.439, 0.524, 0.522, 0.270],\n",
    "    'Sulfate': [0.647, 0.515, 0.562, 0.752, 0.495],\n",
    "    'Conductivity': [0.293, 0.357, 0.143, 0.149, 0.495],\n",
    "    'Organic_carbon': [0.655, 0.377, 0.250, 0.467, 0.410],\n",
    "    'Trihalomethanes': [0.795, 0.203, 0.401, 0.659, 0.470],\n",
    "    'Turbidity': [0.630, 0.520, 0.220, 0.242, 0.585],\n",
    "    'Potability': [0, 0, 0, 0, 0]\n",
    "}\n",
    "\n",
    "\"\"\"Ofcourse, you could also use a random number generator \n",
    "all the way upto 2000 using \n",
    "np.random.rand(2000).tolist() for features\n",
    "and\n",
    "np.random.randint(0,2,2000).tolist() for probabilities i.e., labels\"\"\"\n",
    "\n",
    "# Convert to Pandas DataFrame\n",
    "dataframe = pd.DataFrame(data)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(dataframe)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Extract the features (ph, Sulfate, Conductivity, Organic_carbon) and target (Potability) values and load them into the appropriate tensors to represent features and targets.\n",
    "- Use both tensors to create a PyTorch dataset using the dataset class that's quickest to use when tensors don't require any additional preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the different columns into two PyTorch tensors\n",
    "features = torch.tensor(np.array(dataframe[['ph','Sulfate','Conductivity','Organic_carbon']])).float()\n",
    "target = torch.tensor(np.array(dataframe['Potability'])).float()\n",
    "\n",
    "# Create a dataset from the two generated tensors\n",
    "dataset = TensorDataset(features, target)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Create a PyTorch DataLoader from the created TensorDataset; this DataLoader should use a batch_size of two and shuffle the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataloader using the above dataset\n",
    "dataloader = DataLoader(dataset, batch_size=2, shuffle=True)\n",
    "x, y = next(iter(dataloader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Implement a small, fully connected neural network using exactly two linear layers and the nn.Sequential() API, where the final output size is 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4549],\n",
      "        [0.3141],\n",
      "        [0.4358],\n",
      "        [0.4166],\n",
      "        [0.3012]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Create a model using the nn.Sequential API\n",
    "model = nn.Sequential(\n",
    "                      nn.Linear(4,2),\n",
    "                      nn.Linear(2,1))\n",
    "output = model(features)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
